{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "#test on multiple faces\n",
    "image = face_recognition.load_image_file(\"theboys.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(955, 1311, 1276, 990), (825, 646, 1093, 379), (617, 1568, 885, 1300)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take array of face coordinates and return the index of the largest face\n",
    "def face_selector(faces):\n",
    "    #find the maximum image area from face array\n",
    "    max_area = 0\n",
    "    max_index = 0\n",
    "    for i in range(len(faces)):\n",
    "        x_len = abs(faces[i][2] - faces[i][0])\n",
    "        y_len = abs(faces[i][3] - faces[i][1])\n",
    "        if x_len * y_len > max_area:\n",
    "            max_area = x_len * y_len\n",
    "            max_index = i\n",
    "\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write generalizable function for finding most recognizable faces xD\n",
    "def find_face(image):\n",
    "    #load image\n",
    "    image = face_recognition.load_image_file(image)\n",
    "    #find faces\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    #select face\n",
    "    return face_selector(face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from hashlib import sha512\n",
    "import json\n",
    "face_encodings = {}\n",
    "image = face_recognition.load_image_file(\"theboys.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "max_index = face_selector(face_locations)\n",
    "max_face_encoding = face_recognition.face_encodings(image)[max_index]\n",
    "max_face_encoding.tolist()\n",
    "print(type(max_face_encoding))\n",
    "hex_face = sha512(max_face_encoding)\n",
    "face_encodings[hex_face.hexdigest()] = \"Rishi\"\n",
    "with open(\"encodings.json\", \"w\") as outfile:\n",
    "    json.dump(face_encodings, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.22.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credendtials from environ: service-account-file.json\n",
      "Transcript: yo Arjun I'm recording a flak then I'm going to use as a test audius file just to see what happens and I don't know why I said your name specifically but it's just how it is\n"
     ]
    }
   ],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'service-account-file.json'\n",
    "print('Credendtials from environ: {}'.format(os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')))\n",
    "\n",
    "from google.cloud import speech\n",
    "import os\n",
    "import io\n",
    "\n",
    "# Creates google client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# Full path of the audio file, Replace with your file name\n",
    "file_name = os.path.join(os.path.dirname('./'),\"data.flac\")\n",
    "\n",
    "#Loads the audio file into memory\n",
    "with io.open(file_name, \"rb\") as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "    audio_channel_count=1,\n",
    "    sample_rate_hertz=48000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "# Sends the request to google to transcribe the audio\n",
    "response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "\n",
    "# Reads the response\n",
    "for result in response.results:\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59347453560fcad106dfd147cccf8631e96021aa7abe1bdc27320f4949086d3f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
